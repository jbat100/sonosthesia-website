
.container

    p.quotation (Under construction...)

    h2 Interactive Digital Arts

    p The idea of interactive digital art is not new. It essentially emerged as soon as computer technology allowed it to, continuing a tradition of audio/visual art which preceded it in spirit but was neither digital nor interactive. It was elegantly formulated by Golan Levin on the #[a(href="http://acg.media.mit.edu/people/golan/aves/") Audiovisual Environment Suite] website, a project which goes back to the year 2000.

    div.container
        p.quotation "The Audiovisual Environment Suite [...] allows people to create and perform abstract animation and synthetic sound in real time. [It] attempts to design an interface which is supple and easy to learn, yet can also yield interesting, infinitely variable and personally expressive performances in both the visual and aural domains. Ideally, these systems permit their interactants to engage in a flow state of pure experience. [It is] built around the metaphor of an inexhaustible and dynamic audiovisual substance, which is freely deposited and controlled by the user's gestures. Each instrument situates this substance in a context whose free-form structure inherits from the visual language of abstract painting and animation. The use of low-level synthesis techniques permits the sound and image to be tightly linked, commensurately malleable, and deeply plastic."

    p An extended discussion of the audio/visual arts tradition as well as considerations for a new interface metaphor for digital media, and descriptions of substantial list of important works in the domain can be read in Golan Levin's #[a(href="http://www.flong.com/texts/publications/thesis/") Masters Thesis]. This vision is central to Sonosthesia. We aim to create inter-modal control flows where content generated in different forms of media, by different software components, affect each other in real-time, as well as being influenced by user input in powerfully expressive ways. As computer technology and interaction techniques evolve the possibilities for the real-time creation of complex audio/visual content grow with it, and although a number of projects have since continued Golan's work, opportunities provided by a new generation of tools seem to be yet untapped.


    h2 Cross-modal Control Flows

    p The guideline is the idea of cross-modal control flow between components. The term component is deliberately vague, components produce any combination of visual, audio or haptic content and can run within or across processes, machines or networks. Different components then communicate with and stimulate each other by sending and receiving control streams and mapping between different domains. Determining how these mappings are made is a crucial aspect of the project.

    p As a simple example, a component receives a control stream from a source and reacts to it by producing musical notes and timbral changes. It can then generate descriptors of the content it has generated and feed them into a new control stream of its own. This stream can be piped to another software component (which generates graphical textures, mesh deformations, physical forces in a simulation, or whatever you can imagine).). The next software component in the pipeline receives this control data as input and the can in turn generate content and an associated descriptor output control stream. This control stream can be piped into yet another software component, or several, or looped back to the first component, creating an infinite software control loop. Concrete examples may help.

    h2 Virtual Performance Environments

    p Digital art performance has traditionally suffered from the low-dimensionality of typical control devices (sliders, knobs, keys, sometimes light-beams, touch-tables), these all have only one or two degrees of freedom and fall short of exploiting the huge potential of the human brain, which is revealed for example during virtuosic performances on acoustic instruments. Gestural control has been explored as a human-computer interaction (HCI) vector, addressing the issue of low dimensionality to some extent. However, in current forms gestural interfaces suffer from a lack of context. That is gestures are performed in empty space while we would naturally expect the effect of our gestures to depend on their environmental effects.


    h2 Open Control Protocols for Endless Extension

    p From these concepts should emerge a specification which allows different control flows to be implemented in practise. The objective is a set of interoperable tools, plugins and libraries which allow existing software to interact. Having a rigorously specified protocol will facilitate this. The currently proposed protocol builds on top of OSC, which is very simple yet highly flexible and versatile.

